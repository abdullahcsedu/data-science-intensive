{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Mini Project\n",
    "\n",
    "Import, create, train and make predictions with the sklearn SVC classifier. When creating the classifier, use a linear kernel (if you forget this step, you will be unpleasantly surprised by how long the classifier takes to train). What is the accuracy of the classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "0.984072810011\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n",
    "clf = SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf.predict( features_test)\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "print acc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM Author ID Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n",
    "clf = SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)  \n",
    "t1 = round(time()-t0, 3)\n",
    "print 'training time : ', t1 \n",
    "t2 =  time()\n",
    "#### store your predictions in a list named pred\n",
    "pred = clf.predict( features_test)\n",
    "t3 = round(time()-t2, 3)\n",
    "print 'prediction time : ' ,t3 \n",
    "    \n",
    "if t3 > t1 :\n",
    "    return 'prediction time is higher than training time' ;\n",
    "else :\n",
    "    return  'training time is higher than prediction time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Smaller Training Set\n",
    "\n",
    "One way to speed up an algorithm is to train it on a smaller training dataset. The tradeoff is that the accuracy almost always goes down when you do this. Let’s explore this more concretely: add in the following two lines immediately before training your classifier. \n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "These lines effectively slice the training dataset down to 1% of its original size, tossing out 99% of the training data. You can leave all other code unchanged. What’s the accuracy now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "0.884527872582\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "\n",
    "clf = SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf.predict( features_test)\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "print acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy an RBF Kernel\n",
    "\n",
    "Keep the training set slice code from the last quiz, so that you are still training on only 1% of the full training set. Change the kernel of your SVM to “rbf”. What’s the accuracy now, with this more complex kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "0.616040955631\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "\n",
    "clf = SVC(kernel=\"rbf\")\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf.predict( features_test)\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "print acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize C Parameter\n",
    "\n",
    "Keep the training set size and rbf kernel from the last quiz, but try several values of C (say, 10.0, 100., 1000., and 10000.). Which one gives the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "C Parameter : 1 :   0.616040955631\n",
      "C Parameter1000 :  0.821387940842\n",
      "C Parameter10000 :  0.892491467577\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "\n",
    "clf = SVC(kernel=\"rbf\" , C= 1.0)\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf.predict( features_test)\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "print 'C Parameter : 1 :  ' ,acc\n",
    "\n",
    "clf1 = SVC(kernel=\"rbf\" , C= 1000.0)\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf1.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf1.predict( features_test)\n",
    "acc1 = accuracy_score(pred, labels_test)\n",
    "\n",
    "print 'C Parameter1000 : ' ,acc1\n",
    "\n",
    "clf1 = SVC(kernel=\"rbf\" , C= 10000.0)\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf1.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf1.predict( features_test)\n",
    "acc1 = accuracy_score(pred, labels_test)\n",
    "\n",
    "print 'C Parameter10000 : ' ,acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized RBF vs. Linear SVM: Accuracy\n",
    "\n",
    "Now that you’ve optimized C for the RBF kernel, go back to using the full training set. In general, having a larger training set will improve the performance of your algorithm, so (by tuning C and training on a large dataset) we should get a fairly optimized result. What is the accuracy of the optimized SVM?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "0.990898748578\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "#features_train = features_train[:len(features_train)/100] \n",
    "# labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "\n",
    "clf = SVC(kernel=\"rbf\" , C = 10000.0 )\n",
    "\n",
    "\n",
    "#### now your job is to fit the classifier\n",
    "#### using the training features/labels, and to\n",
    "#### make a set of predictions on the test data\n",
    "clf.fit(features_train, labels_train)  \n",
    "#### store your predictions in a list named pred\n",
    "pred = clf.predict( features_test)\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Predictions from an SVM\n",
    "\n",
    "What class does your SVM (0 or 1, corresponding to Sara and Chris respectively) predict for element 10 of the test set? The 26th? The 50th? (Use the RBF kernel, C=10000, and 1% of the training set. Normally you'd get the best results using the full training set, but we found that using 1% sped up the computation considerably and did not change our results--so feel free to use that shortcut here.)\n",
    "And just to be clear, the data point numbers that we give here (10, 26, 50) assume a zero-indexed list. So the correct answer for element #100 would be found using something like answer=predictions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[10] ,pred[26],pred[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Many Chris Emails Predicted?\n",
    "There are over 1700 test events--how many are predicted to be in the “Chris” (1) class? (Use the RBF kernel, C=10000., and the full training set.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1758"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "chris_emails = 0 ;\n",
    "sara_emails = 0\n",
    "for item in pred :\n",
    "    if(item == 1):\n",
    "        chris_emails =  chris_emails + 1\n",
    "    else : \n",
    "        sara_emails = sara_emails+1\n",
    "print chris_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
